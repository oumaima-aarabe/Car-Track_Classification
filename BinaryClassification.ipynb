{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1495782,"sourceType":"datasetVersion","datasetId":878523},{"sourceId":9732126,"sourceType":"datasetVersion","datasetId":5955810},{"sourceId":9732141,"sourceType":"datasetVersion","datasetId":5955821}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/oumaimaaarabe/car-track?scriptVersionId=203704860\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"## load data","metadata":{"execution":{"iopub.status.busy":"2024-10-25T14:25:19.352961Z","iopub.execute_input":"2024-10-25T14:25:19.353415Z","iopub.status.idle":"2024-10-25T14:25:19.358845Z","shell.execute_reply.started":"2024-10-25T14:25:19.353372Z","shell.execute_reply":"2024-10-25T14:25:19.357428Z"}}},{"cell_type":"code","source":"# Imports\nimport os, warnings\nimport matplotlib.pyplot as plt\nfrom matplotlib import gridspec\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\n\nwarnings.filterwarnings(\"ignore\")\n\ndef warn(*args, **kwargs):\n    pass\nwarnings.warn = warn\n# Reproducability\nVALIDATION_SPLIT = 0.5  # Split test data 50-50 between validation and test\nSEED = 123  # For reproducibility\nBATCH_SIZE = 64\nIMAGE_SIZE = [128, 128]\n\n# Load training data (no split needed)\nds_train = image_dataset_from_directory(\n    '../input/car-or-truck/train',\n    labels='inferred',\n    label_mode='binary',\n    image_size=IMAGE_SIZE,\n    interpolation='nearest',\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n)\n\n# Split the test directory into validation and test sets\nds_val = image_dataset_from_directory(\n    '../input/car-or-truck/valid',\n    labels='inferred',\n    label_mode='binary',\n    image_size=IMAGE_SIZE,\n    interpolation='nearest',\n    batch_size=BATCH_SIZE,\n    validation_split=VALIDATION_SPLIT,\n    subset='training',  # This will be our validation set\n    seed=SEED,\n    shuffle=True,\n)\n\nds_test = image_dataset_from_directory(\n    '../input/car-or-truck/valid',  \n    labels='inferred',\n    label_mode='binary',\n    image_size=IMAGE_SIZE,\n    interpolation='nearest',\n    batch_size=BATCH_SIZE,\n    validation_split=VALIDATION_SPLIT,\n    subset='validation',  # This will be our test set\n    seed=SEED,\n    shuffle=True,\n)\n# Data Pipeline\ndef convert_to_float(image, label):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nds_train = (\n    ds_train\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\nds_valid = (\n    ds_val\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)\n\nds_test = (\n    ds_test\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T07:52:28.908804Z","iopub.execute_input":"2024-10-27T07:52:28.909178Z","iopub.status.idle":"2024-10-27T07:52:41.193048Z","shell.execute_reply.started":"2024-10-27T07:52:28.909143Z","shell.execute_reply":"2024-10-27T07:52:41.19222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define && Train Model","metadata":{}},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\n\n\n# # detect and init the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n\n# # instantiate a distribution strategy\n# tf.tpu.experimental.initialize_tpu_system(tpu)\n# tpu_strategy = tf.distribute.TPUStrategy(tpu)\n\n# # instantiating the model in the strategy scope creates the model on the TPU\n# with tpu_strategy.scope():\n\n\n\ndef create_model():\n    model = keras.Sequential([\n\n        # First Convolutional Block\n        layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\", padding='same',\n                      # [height, width, color channels(RGB)]\n                      input_shape=[128, 128, 3]),\n        layers.AveragePooling2D(2),\n\n        # Second Convolutional Block\n        layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n        layers.AveragePooling2D(2),\n\n        # Third Convolutional Block\n        layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n        layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n        layers.AveragePooling2D(2),\n\n        # Classifier Head\n        layers.Flatten(),\n        layers.Dense(units=6, activation=\"relu\"),\n        layers.Dropout(0.2),\n        layers.Dense(units=1, activation=\"sigmoid\"),\n    ])\n    \n    model.compile(\n            optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n            loss='binary_crossentropy',\n            metrics=[keras.metrics.BinaryAccuracy()],\n    )\n    return model\n\n\nearly_stopping = keras.callbacks.EarlyStopping(\n    min_delta=0.001,\n    patience=12,\n    restore_best_weights=True,\n    verbose=1)\n\nReduceLROnPlateau = keras.callbacks.ReduceLROnPlateau(\n    monitor=\"val_loss\",\n    factor=0.1,\n    patience=6,\n    verbose=1,\n    mode=\"min\",\n)\n\n\nModelCheckpoint = tf.keras.callbacks.ModelCheckpoint(\n    \"truckOrCar.keras\",\n    monitor='val_loss',\n    verbose=1,\n    save_best_only=True,\n    mode='min',\n)\nmodel = create_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-10-27T07:58:56.172708Z","iopub.execute_input":"2024-10-27T07:58:56.173096Z","iopub.status.idle":"2024-10-27T07:58:56.270807Z","shell.execute_reply.started":"2024-10-27T07:58:56.173057Z","shell.execute_reply":"2024-10-27T07:58:56.269421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tf.config.optimizer.set_jit(False)\nhistory = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=50,\n    verbose=1,\n    callbacks=[early_stopping, ReduceLROnPlateau, ModelCheckpoint]\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T07:58:59.227275Z","iopub.execute_input":"2024-10-27T07:58:59.227676Z","iopub.status.idle":"2024-10-27T07:59:52.934693Z","shell.execute_reply.started":"2024-10-27T07:58:59.227639Z","shell.execute_reply":"2024-10-27T07:59:52.933783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['loss', 'val_loss']].plot()\nhistory_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();","metadata":{"execution":{"iopub.status.busy":"2024-10-27T07:53:55.851995Z","iopub.execute_input":"2024-10-27T07:53:55.852309Z","iopub.status.idle":"2024-10-27T07:53:56.749392Z","shell.execute_reply.started":"2024-10-27T07:53:55.852275Z","shell.execute_reply":"2024-10-27T07:53:56.74839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n# Replace 'your_image.jpg' with the actual filename of your uploaded image\nimg_path_c = '/kaggle/input/test-image/WHITE_cc_2022HOC020101_01_1280_BL.jpeg'\nimg_path = '/kaggle/input/truck-test/download_image.jpeg'\n\n# Load the image using tf.keras.preprocessing.image.load_img\nimg = tf.keras.preprocessing.image.load_img(img_path_c, target_size=(128, 128))\n\n# Convert the image to a NumPy array\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\n\n# Preprocess the image (e.g., normalize pixel values)\nimg_array = img_array / 255.0  # Normalize pixel values to [0, 1]\n\n# Add an extra dimension to represent the batch size\nimg_array = tf.expand_dims(img_array, 0)\n\npredictions = model.predict(img_array)\nprint(predictions)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T07:53:56.750682Z","iopub.execute_input":"2024-10-27T07:53:56.751009Z","iopub.status.idle":"2024-10-27T07:53:57.15136Z","shell.execute_reply.started":"2024-10-27T07:53:56.750972Z","shell.execute_reply":"2024-10-27T07:53:57.150331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save('car_or_truck_model')\nloss, acc = model.evaluate(ds_test, verbose=2)\nprint(\"Untrained model, accuracy: {:5.2f}%\".format(100 * acc))","metadata":{"execution":{"iopub.status.busy":"2024-10-27T07:54:02.183872Z","iopub.execute_input":"2024-10-27T07:54:02.184269Z","iopub.status.idle":"2024-10-27T07:54:02.712363Z","shell.execute_reply.started":"2024-10-27T07:54:02.184224Z","shell.execute_reply":"2024-10-27T07:54:02.711449Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
